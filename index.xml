<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Yang</title><link>https://Yangliuly1.github.io/</link><description>Yang</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>yangliuly1993@gmail.com (Yangliuly1)</managingEditor><webMaster>yangliuly1993@gmail.com (Yangliuly1)</webMaster><lastBuildDate>Mon, 09 May 2022 09:51:06 +0800</lastBuildDate><atom:link href="https://Yangliuly1.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Wide Residual Networks</title><link>https://Yangliuly1.github.io/201605-wideresnet/</link><pubDate>Mon, 09 May 2022 09:51:06 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201605-wideresnet/</guid><description>&lt;p>摘要：WideResNet（WRN），2016年Sergey Zagoruyko发表，从增加网络宽度角度改善ResNet，性能和训练速度都提升。&lt;/p></description></item><item><title>Regularized Evolution for Image Classifier Architecture Search</title><link>https://Yangliuly1.github.io/201804-amoebanet/</link><pubDate>Sun, 08 May 2022 01:03:50 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201804-amoebanet/</guid><description>&lt;p>摘要：AmoebaNet是通过遗传算法的进化策略（Evolution）实现的模型结构的学习过程。&lt;/p></description></item><item><title>Learning Transferable Architectures for Scalable Image Recognition</title><link>https://Yangliuly1.github.io/201707-nasnet/</link><pubDate>Sat, 07 May 2022 23:18:52 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201707-nasnet/</guid><description>&lt;p>摘要：cvpr2017 google brain作品，利用强化学习，使用500块p100训练4天多得到的网络结构NASNet，在小数据（CIFAR-10）上学习一个网络单元（Cell），然后通过堆叠更多的这些网络单元的形式将网络迁移到更复杂，尺寸更大的数据集上面，不管在精度还是在速度上都超越了人工设计的经典结构。&lt;/p></description></item><item><title>ShuffleNet V2, Practical Guidelines for Efficient CNN Architecture Design</title><link>https://Yangliuly1.github.io/201807-shufflenet-v2/</link><pubDate>Sat, 07 May 2022 15:09:04 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201807-shufflenet-v2/</guid><description>&lt;p>摘要：ShuffleNet v2中以内存访问代价（Memory Access Cost，MAC）和GPU并行性的方向分析网络效率。&lt;/p></description></item><item><title>ShuffleNet, An Extremely Efficient Convolutional Neural Network for Mobile Devices</title><link>https://Yangliuly1.github.io/201701-shufflenet-v1/</link><pubDate>Sat, 07 May 2022 11:09:59 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201701-shufflenet-v1/</guid><description>&lt;p>摘要：ShuffleNet 解决分组卷积的计算量和特征通信问题。&lt;/p></description></item></channel></rss>