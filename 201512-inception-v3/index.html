<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title class=pjax-title>Rethinking the Inception Architecture for Computer - Yang</title><meta name=Description content><meta property="og:title" content="Rethinking the Inception Architecture for Computer"><meta property="og:description" content="摘要：针对计算效率方面的作用，提出了分解卷积等思想。"><meta property="og:type" content="article"><meta property="og:url" content="https://Yangliuly1.github.io/201512-inception-v3/"><meta property="og:image" content="https://Yangliuly1.github.io/images/avatar.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-04-27T14:59:17+08:00"><meta property="article:modified_time" content="2022-04-27T14:59:17+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://Yangliuly1.github.io/images/avatar.png"><meta name=twitter:title content="Rethinking the Inception Architecture for Computer"><meta name=twitter:description content="摘要：针对计算效率方面的作用，提出了分解卷积等思想。"><meta name=application-name content="Yang"><meta name=apple-mobile-web-app-title content="Yang"><meta name=theme-color content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://Yangliuly1.github.io/201512-inception-v3/><link rel=prev href=https://Yangliuly1.github.io/201504-inception-v2/><link rel=next href=https://Yangliuly1.github.io/201602-inception-v4/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/fontawesome-free/all.min.css><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/animate/animate.min.css><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Rethinking the Inception Architecture for Computer","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/Yangliuly1.github.io\/201512-inception-v3\/"},"genre":"posts","keywords":"图像分类","wordcount":140,"url":"https:\/\/Yangliuly1.github.io\/201512-inception-v3\/","datePublished":"2022-04-27T14:59:17+08:00","dateModified":"2022-04-27T14:59:17+08:00","publisher":{"@type":"Organization","name":"Yangliuly1"},"author":{"@type":"Person","name":"Yangliuly1"},"description":""}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>function setTheme(e){document.body.setAttribute("theme",e),document.documentElement.style.setProperty("color-scheme",e==="light"?"light":"dark")}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(e){const t=document.getElementsByTagName("meta");for(let n=0;n<t.length;n++)if(t[n].getAttribute("name")===e)return t[n];return""}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"||e==="black"?setTheme(e):setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")}else"auto"==="light"||"auto"==="dark"||"auto"==="black"?(setTheme("auto"),saveTheme("auto")):(saveTheme("auto"),setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"));let metaColors={light:"#f8f8f8",dark:"#252627",black:"#000000"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")]</script><div id=back-to-top></div><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=Yang><span class=header-title-pre><i class='far fa-edit fa-fw'></i></span><span id=desktop-header-typeit class=typeit></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/about/>关于 </a><a class=menu-item href=https://github.com/Yangliuly1 title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i> </a><span class="menu-item delimiter"></span><a href=# onclick=return!1 class="menu-item theme-select" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
<select class=color-theme-select id=theme-select-desktop title="Switch Theme"><option value=light>Light</option><option value=dark>Dark</option><option value=black>Black</option><option value=auto>Auto</option></select></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=Yang><span class=header-title-pre><i class='far fa-edit fa-fw'></i></span><span id=mobile-header-typeit class=typeit></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/about/ title>关于</a><a class=menu-item href=https://github.com/Yangliuly1 title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i></a><a href=# onclick=return!1 class="menu-item theme-select" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
<select class=color-theme-select id=theme-select-mobile title="Switch Theme"><option value=light>Light</option><option value=dark>Dark</option><option value=black>Black</option><option value=auto>Auto</option></select></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class="toc-content always-active" id=toc-content-auto><nav id=TableOfContents><ul><li><a href=#文献信息>文献信息</a></li><li><a href=#个人理解>个人理解</a></li><li><a href=#原理方法>原理方法</a><ul><li><a href=#1设计准则>1、设计准则</a></li><li><a href=#2分解卷积核尺寸>2、分解卷积核尺寸</a></li><li><a href=#3使用辅助分类器>3、使用辅助分类器</a></li><li><a href=#4高效降低特征图尺寸的方式>4、高效降低特征图尺寸的方式</a></li><li><a href=#5inception-v3网络结构>5、Inception v3网络结构</a></li><li><a href=#6label-smoothing模型正则02>6、Label Smoothing模型正则</a></li><li><a href=#7在低分辨率输入情况下的性能>7、在低分辨率输入情况下的性能</a></li></ul></li><li><a href=#实验结果>实验结果</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></div><script>document.getElementsByTagName("main")[0].setAttribute("pageStyle","normal")</script><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","true")</script><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Rethinking the Inception Architecture for Computer</h1><div class=post-meta><div class=post-meta-line><span class=post-author><i class="author fas fa-user-circle fa-fw"></i><a href=/about/ title=Author rel=author class=author>Yangliuly1</a>
</span>&nbsp;<span class=post-category>included in </span>&nbsp;<span class=post-category>category <a href=/categories/%E4%B8%93%E4%B8%9A%E8%AE%BA%E6%96%87/><i class="far fa-folder fa-fw"></i>专业论文</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2022-04-27>2022-04-27</time>&nbsp;<i class="far fa-edit fa-fw"></i>&nbsp;<time datetime=2022-04-27>2022-04-27</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;140 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;One minute&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#文献信息>文献信息</a></li><li><a href=#个人理解>个人理解</a></li><li><a href=#原理方法>原理方法</a><ul><li><a href=#1设计准则>1、设计准则</a></li><li><a href=#2分解卷积核尺寸>2、分解卷积核尺寸</a></li><li><a href=#3使用辅助分类器>3、使用辅助分类器</a></li><li><a href=#4高效降低特征图尺寸的方式>4、高效降低特征图尺寸的方式</a></li><li><a href=#5inception-v3网络结构>5、Inception v3网络结构</a></li><li><a href=#6label-smoothing模型正则02>6、Label Smoothing模型正则</a></li><li><a href=#7在低分辨率输入情况下的性能>7、在低分辨率输入情况下的性能</a></li></ul></li><li><a href=#实验结果>实验结果</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></div><div class=content id=content><p>摘要：针对计算效率方面的作用，提出了分解卷积等思想。</p><h1 id=rethinking-the-inception-architecture-for-computer0102 class=headerLink><a href=#rethinking-the-inception-architecture-for-computer0102 class=header-mark></a>Rethinking the Inception Architecture for Computer<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup><sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></h1><h2 id=文献信息 class=headerLink><a href=#%e6%96%87%e7%8c%ae%e4%bf%a1%e6%81%af class=header-mark></a>文献信息</h2><table><thead><tr><th>信息</th><th>内容</th></tr></thead><tbody><tr><td>日期</td><td>2015.12</td></tr><tr><td>作者</td><td>Christian Szegedy et al.</td></tr><tr><td>机构</td><td>Google Inc</td></tr><tr><td>来源</td><td>arXiv</td></tr><tr><td>链接</td><td><a href=https://arxiv.org/abs/1512.00567 target=_blank rel="noopener noreffer">Rethinking the Inception Architecture for Computer</a></td></tr><tr><td>代码</td><td><a href rel>Code</a></td></tr></tbody></table><h2 id=个人理解 class=headerLink><a href=#%e4%b8%aa%e4%ba%ba%e7%90%86%e8%a7%a3 class=header-mark></a>个人理解</h2><blockquote><p><strong style=color:red>问题:</strong> Inception v1的计算量，尤其是通道上，计算量和channel的平方成正比；</p><p><strong style=color:red>方法:</strong> 文章提出了网络设计准则，分解卷积核设计，辅助分类支路，分辨率下降优化、标签平衡、高分辨率输入等技巧；</p><p><strong style=color:red>结论:</strong> ILSVRC 2012，21.2%top-1错误率和5.6%top-5错误率，四模型融合平均17.3%top-1错误率和3.5%top-5错误率；</p><p><strong style=color:red>理解:</strong> 核心思想是可分解卷积核和正则化，对Inception结构维度减少和并行结构。</p><p><strong style=color:red>优化：</strong>。</p></blockquote><hr><h2 id=原理方法 class=headerLink><a href=#%e5%8e%9f%e7%90%86%e6%96%b9%e6%b3%95 class=header-mark></a>原理方法</h2><h3 id=1设计准则 class=headerLink><a href=#1%e8%ae%be%e8%ae%a1%e5%87%86%e5%88%99 class=header-mark></a>1、设计准则</h3><ol><li>避免代表性（表现上）瓶颈，尤其是在网络早期。<ul><li>通常，在达到任务的最终表示之前，表示大小应该从输入到输出逐渐减小。</li><li>维度信息仅提供对信息内容的粗略估计。</li></ul></li><li>更高维的表示更容易在网络内本地处理。<ul><li>增加卷积网络中每个图块的激活次数可以实现更多解开的特征。由此产生的网络将训练得更快。</li></ul></li><li>空间聚合可以在较低维度的嵌入上完成，而不会损失太多或任何表示能力。<ul><li>例如，在执行更分散（例如 3 × 3）卷积之前，可以在空间聚合之前减少输入表示的维度，而不会产生严重的不利影响。</li><li>我们假设其原因是相邻单元之间的强相关性导致降维期间信息丢失少得多，如果输出用于空间聚合上下文。</li><li>鉴于这些信号应该很容易压缩，降维甚至可以促进更快的学习。</li></ul></li><li>平衡网络的宽度和深度。</li></ol><h3 id=2分解卷积核尺寸 class=headerLink><a href=#2%e5%88%86%e8%a7%a3%e5%8d%b7%e7%a7%af%e6%a0%b8%e5%b0%ba%e5%af%b8 class=header-mark></a>2、分解卷积核尺寸</h3><p>第一种方法：分解为对称的小的卷积核，VGG中的思想，将5x5的卷积核替换成2个3x3的卷积核。</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220427154335337.png width=25%> <img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220427154340217.png width=25%></div><p>第二种方法：分解为不对称的卷积核，将nxn的卷积核替换成 1xn 和 nx1 的卷积核堆叠，计算量又会降低。但是第二种分解方法在大维度的特征图上表现不好，在特征图12-20维度上表现好。</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220427154450936.png width=25%> <img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220427154529752.png width=25%></div><p>不对称分解方法有几个优点：</p><ul><li>节约了大量的参数</li><li>增加一层非线性，提高模型的表达能力</li><li>可以处理更丰富的空间特征，增加特征的多样性</li></ul><h3 id=3使用辅助分类器 class=headerLink><a href=#3%e4%bd%bf%e7%94%a8%e8%be%85%e5%8a%a9%e5%88%86%e7%b1%bb%e5%99%a8 class=header-mark></a>3、使用辅助分类器</h3><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220427154651191.png width=75%></div><p>在第一篇论文中GoogLeNet中就使用了辅助分类器，使用了2个，但前期不会加速拟合，后期的准确率会有些微的提高。其优势：</p><ul><li>把梯度有效的传递回去，不会有梯度消失问题，加快了训练。</li><li>中间层的特征也有意义，空间位置特征比较丰富，有利于提成模型的判别力。</li></ul><h3 id=4高效降低特征图尺寸的方式 class=headerLink><a href=#4%e9%ab%98%e6%95%88%e9%99%8d%e4%bd%8e%e7%89%b9%e5%be%81%e5%9b%be%e5%b0%ba%e5%af%b8%e7%9a%84%e6%96%b9%e5%bc%8f class=header-mark></a>4、高效降低特征图尺寸的方式</h3><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220427154914072.png width=35%>
<img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220427154807784.png width=35%></div><p>设计准则的第一条，就是避免表达瓶颈。那么传统的卷积神经网络的做法，当有pooling时（pooling层会大量的损失信息），会在之前增加特征图的厚度（就是双倍增加滤波器的个数），通过这种方式来保持网络的表达能力，但是计算量会大大增加。</p><p>优化：分离两个通道，一个是卷积层，一个是pooling层，两个通道生成的特征图大小一样，concat在一起即可。</p><h3 id=5inception-v3网络结构 class=headerLink><a href=#5inception-v3%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84 class=header-mark></a>5、Inception v3网络结构</h3><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220427154209135.png width=50%></div><p>Inception v2不同的是，作者将7x7卷积分解成了三个3x3卷积。网络中有三个Inception模组，三个模组的结构分别采用 图5、6、7三种结构。inception模块中的gird size reduction方法采用的是图10结构。
我们可以看到，网络的质量与第二节说的准则有很大关系。尽管我们的网络深达42层，但我们的计算量仅仅是GoogLeNet的2.5倍，并且，它比VGG更高效。</p><h3 id=6label-smoothing模型正则02 class=headerLink><a href=#6label-smoothing%e6%a8%a1%e5%9e%8b%e6%ad%a3%e5%88%9902 class=header-mark></a>6、Label Smoothing模型正则<sup id=fnref1:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></h3><p>针对cross-entropy loss的缺点，即必须使得对应真值的logit过大。原因在于softmax公式： $p(k|x) = \frac{exp(z_k)}{\sum_{i=1}^{K}exp(z_i)}$ ，要使 $p(k|x) = 1$ 需使得$exp(z_k) = \sum_{i=1}^{K}exp(z_i)$ 即 $\sum_{i=1,i!=k}^{K}exp(z_i) = 0$，当然这个是理想情况，一般导致的结果就是$(z_i)_{i!=k} &#171; z_k$。</p><ol><li>这可能会导致过度拟合：如果模型学会为每个训练示例为真实标签分配完整概率，则不能保证泛化。</li><li>它鼓励最大logit与所有其他logit之间的差异变大，而这个最大logit和所有其他logit之间的差异变大，并且与有界梯度相结合，降低了模型的适应能力。 直观地说，这是因为模型对其预测过于自信。</li></ol><p>作者提出了一个正则化方法LSR(label-smoothing regularization)：对比之前的真值分布$p(k|x) = \delta_{k,y}$，LSR提出的真值分布是：</p><p>$$
q^{\prime}(k)=(1-\epsilon) \delta_{k, y}+\frac{\epsilon}{K}
$$</p><p>因为$\epsilon$是一个小的正数，所以对应真值($\delta_{k, y} = 1$)的大小是$q^{\prime}(k)=1 - \frac{K-1}{K}\epsilon$ ，可见基本相当于1减掉一个小数，防止无限趋于0，对应非真值($\delta_{k, y} = 0$)的大小是 $q^{\prime}(k)=\frac{\epsilon}{K}\epsilon$ ，是比$\epsilon$更小的一个数，防止其为0罢了。</p><h3 id=7在低分辨率输入情况下的性能 class=headerLink><a href=#7%e5%9c%a8%e4%bd%8e%e5%88%86%e8%be%a8%e7%8e%87%e8%be%93%e5%85%a5%e6%83%85%e5%86%b5%e4%b8%8b%e7%9a%84%e6%80%a7%e8%83%bd class=header-mark></a>7、在低分辨率输入情况下的性能</h3><p>研究分辨率的影响是为了搞清楚：高分辨率是否有助于性能的提升，能提高多少？</p><p>一个简单方法是在较低分辨率输入的情况下减少前两层的步幅，或者简单地删除网络的第一个池化层。</p><p>但作者采用了三种分辨率的图像作为输入。三种情况的计算量是几乎相同的。此外，表 2 的这些结果表明，可以考虑在 R-CNN [5] 上下文中为较小的对象使用专用的高成本低分辨率网络。</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220427155106542.png width=75%></div><h2 id=实验结果 class=headerLink><a href=#%e5%ae%9e%e9%aa%8c%e7%bb%93%e6%9e%9c class=header-mark></a>实验结果</h2><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220427155714507.png width=50%>
<img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220427155735269.png width=50%>
<img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220427155745538.png width=50%></div><h2 id=参考文献 class=headerLink><a href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae class=header-mark></a>参考文献</h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://blog.csdn.net/chairon/article/details/119445971 target=_blank rel="noopener noreffer">chairon-Inception V3-CSDN</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=https://zhuanlan.zhihu.com/p/50751422 target=_blank rel="noopener noreffer">Michael-深入解读Inception V3-知乎</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2022-04-27</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/>图像分类</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/201504-inception-v2/ class=prev rel=prev title="Batch Normalization, Accelerating Deep Network Training by Reducing Internal Covariate Shift"><i class="fas fa-angle-left fa-fw"></i>Batch Normalization, Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>
<a href=/201602-inception-v4/ class=next rel=next title="Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning">Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2022</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/about/ target=_blank rel="noopener noreferrer">Yangliuly1</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class=footer-line></div><div class=footer-line></div></div><script>"serviceWorker"in navigator&&(navigator.serviceWorker.register("/sw.min.js",{scope:"/"}).then(function(){}),navigator.serviceWorker.ready.then(function(){}))</script></footer></div><div id=fixed-buttons><a href=#back-to-top id=back-to-top-button class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><div class=assets><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/tablesort/tablesort.min.js></script><script type=text/javascript src=/lib/topbar/topbar.min.js></script><script type=text/javascript src=/lib/pjax/pjax.min.js></script><script type=text/javascript src=/js/theme.min.js defer></script></div><div class=pjax-assets><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:10},comment:{},data:{"desktop-header-typeit":"日落跌进迢迢星野,人间忽晚,山河已秋!","mobile-header-typeit":"日落跌进迢迢星野,人间忽晚,山河已秋!"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},table:{sort:!0},typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"desktop-header-typeit":["desktop-header-typeit"],"mobile-header-typeit":["mobile-header-typeit"]},duration:-1,speed:100}}</script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/typeit/typeit.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js defer></script><script type=text/javascript src=/lib/katex/auto-render.min.js defer></script><script type=text/javascript src=/lib/katex/copy-tex.min.js defer></script><script type=text/javascript src=/lib/katex/mhchem.min.js defer></script><script type=text/javascript src=/js/katex.min.js defer></script><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/copy-tex.min.css><noscript><link rel=stylesheet href=/lib/katex/copy-tex.min.css></noscript></div></body></html>