<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title class=pjax-title>Coordinate Attention for Efficient Mobile Network Design - Yang</title><meta name=Description content><meta property="og:title" content="Coordinate Attention for Efficient Mobile Network Design"><meta property="og:description" content="摘要：CA通过2D全局池将特征张量转换为单个特征向量的通道关注不同，坐标关注将通道关注分解为两个1D特征编码过程，分别沿两个空间方向聚合特征。 这样，可以沿一个空间方向捕获远程依赖关系，同时可以沿另一空间方向保留精确的位置信息。然后将生成的特征图分别编码为一对方向感知和位置敏感的注意图，可以将其互补地应用于输入特征图，以增强关注对象的表示。"><meta property="og:type" content="article"><meta property="og:url" content="https://Yangliuly1.github.io/202103-ca/"><meta property="og:image" content="https://Yangliuly1.github.io/images/avatar.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-05-10T10:05:03+08:00"><meta property="article:modified_time" content="2022-05-10T10:05:03+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://Yangliuly1.github.io/images/avatar.png"><meta name=twitter:title content="Coordinate Attention for Efficient Mobile Network Design"><meta name=twitter:description content="摘要：CA通过2D全局池将特征张量转换为单个特征向量的通道关注不同，坐标关注将通道关注分解为两个1D特征编码过程，分别沿两个空间方向聚合特征。 这样，可以沿一个空间方向捕获远程依赖关系，同时可以沿另一空间方向保留精确的位置信息。然后将生成的特征图分别编码为一对方向感知和位置敏感的注意图，可以将其互补地应用于输入特征图，以增强关注对象的表示。"><meta name=application-name content="Yang"><meta name=apple-mobile-web-app-title content="Yang"><meta name=theme-color content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://Yangliuly1.github.io/202103-ca/><link rel=prev href=https://Yangliuly1.github.io/201807-cbma/><link rel=next href=https://Yangliuly1.github.io/201905-efficientnet/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/fontawesome-free/all.min.css><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/animate/animate.min.css><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Coordinate Attention for Efficient Mobile Network Design","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/Yangliuly1.github.io\/202103-ca\/"},"genre":"posts","keywords":"图像分类","wordcount":183,"url":"https:\/\/Yangliuly1.github.io\/202103-ca\/","datePublished":"2022-05-10T10:05:03+08:00","dateModified":"2022-05-10T10:05:03+08:00","publisher":{"@type":"Organization","name":"Yangliuly1"},"author":{"@type":"Person","name":"Yangliuly1"},"description":""}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>function setTheme(e){document.body.setAttribute("theme",e),document.documentElement.style.setProperty("color-scheme",e==="light"?"light":"dark")}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(e){const t=document.getElementsByTagName("meta");for(let n=0;n<t.length;n++)if(t[n].getAttribute("name")===e)return t[n];return""}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"||e==="black"?setTheme(e):setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")}else"auto"==="light"||"auto"==="dark"||"auto"==="black"?(setTheme("auto"),saveTheme("auto")):(saveTheme("auto"),setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"));let metaColors={light:"#f8f8f8",dark:"#252627",black:"#000000"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")]</script><div id=back-to-top></div><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=Yang><span class=header-title-pre><i class='far fa-edit fa-fw'></i></span><span id=desktop-header-typeit class=typeit></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/about/>关于 </a><a class=menu-item href=https://github.com/Yangliuly1 title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i> </a><span class="menu-item delimiter"></span><a href=# onclick=return!1 class="menu-item theme-select" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
<select class=color-theme-select id=theme-select-desktop title="Switch Theme"><option value=light>Light</option><option value=dark>Dark</option><option value=black>Black</option><option value=auto>Auto</option></select></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=Yang><span class=header-title-pre><i class='far fa-edit fa-fw'></i></span><span id=mobile-header-typeit class=typeit></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/about/ title>关于</a><a class=menu-item href=https://github.com/Yangliuly1 title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i></a><a href=# onclick=return!1 class="menu-item theme-select" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
<select class=color-theme-select id=theme-select-mobile title="Switch Theme"><option value=light>Light</option><option value=dark>Dark</option><option value=black>Black</option><option value=auto>Auto</option></select></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class="toc-content always-active" id=toc-content-auto><nav id=TableOfContents><ul><li><a href=#文献信息>文献信息</a></li><li><a href=#个人理解>个人理解</a></li><li><a href=#背景知识>背景知识</a></li><li><a href=#原理方法>原理方法</a><ul><li><a href=#1coordinate-attention>1、Coordinate Attention</a></li><li><a href=#2coordinate-attention生成>2、Coordinate Attention生成</a></li><li><a href=#3ca嵌入方式>3、CA嵌入方式</a></li></ul></li><li><a href=#实验结果>实验结果</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></div><script>document.getElementsByTagName("main")[0].setAttribute("pageStyle","normal")</script><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","true")</script><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Coordinate Attention for Efficient Mobile Network Design</h1><div class=post-meta><div class=post-meta-line><span class=post-author><i class="author fas fa-user-circle fa-fw"></i><a href=/about/ title=Author rel=author class=author>Yangliuly1</a>
</span>&nbsp;<span class=post-category>included in </span>&nbsp;<span class=post-category>category <a href=/categories/%E4%B8%93%E4%B8%9A%E8%AE%BA%E6%96%87/><i class="far fa-folder fa-fw"></i>专业论文</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2022-05-10>2022-05-10</time>&nbsp;<i class="far fa-edit fa-fw"></i>&nbsp;<time datetime=2022-05-10>2022-05-10</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;183 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;One minute&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#文献信息>文献信息</a></li><li><a href=#个人理解>个人理解</a></li><li><a href=#背景知识>背景知识</a></li><li><a href=#原理方法>原理方法</a><ul><li><a href=#1coordinate-attention>1、Coordinate Attention</a></li><li><a href=#2coordinate-attention生成>2、Coordinate Attention生成</a></li><li><a href=#3ca嵌入方式>3、CA嵌入方式</a></li></ul></li><li><a href=#实验结果>实验结果</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></div><div class=content id=content><p>摘要：CA通过2D全局池将特征张量转换为单个特征向量的通道关注不同，<strong>坐标关注将通道关注分解为两个1D特征编码过程，分别沿两个空间方向聚合特征。</strong> 这样，可以沿一个空间方向捕获远程依赖关系，同时可以沿另一空间方向保留精确的位置信息。然后将生成的特征图分别编码为一对方向感知和位置敏感的注意图，可以将其互补地应用于输入特征图，以增强关注对象的表示。</p><h1 id=coordinate-attention-for-efficient-mobile-network-design01 class=headerLink><a href=#coordinate-attention-for-efficient-mobile-network-design01 class=header-mark></a>Coordinate Attention for Efficient Mobile Network Design<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></h1><h2 id=文献信息 class=headerLink><a href=#%e6%96%87%e7%8c%ae%e4%bf%a1%e6%81%af class=header-mark></a>文献信息</h2><table><thead><tr><th>信息</th><th>内容</th></tr></thead><tbody><tr><td>日期</td><td>2021.04</td></tr><tr><td>作者</td><td>Qibin Hou et al.</td></tr><tr><td>机构</td><td>National University of Singapore</td></tr><tr><td>来源</td><td>cvpr2021</td></tr><tr><td>链接</td><td><a href=http://arxiv.org/abs/2103.02907 target=_blank rel="noopener noreffer">Coordinate Attention for Efficient Mobile Network Design</a></td></tr><tr><td>代码</td><td><a href=https://github.com/Andrew-Qibin/CoordAttention target=_blank rel="noopener noreffer">Andrew-Qibin/CoordAttention</a></td></tr></tbody></table><h2 id=个人理解 class=headerLink><a href=#%e4%b8%aa%e4%ba%ba%e7%90%86%e8%a7%a3 class=header-mark></a>个人理解</h2><blockquote><p><strong style=color:red>问题:</strong> 注意力机制问题；</p><p><strong style=color:red>方法:</strong> 分离x和y方向，分别计算注意力机制，构建Coordinate Attention；</p><p><strong style=color:red>结论:</strong> 协调注意不仅有利于ImageNet分类，而且更有趣的是，它在下游任务中表现得更好，例如目标检测和语义分割；</p><p><strong style=color:red>理解:</strong></p><ol><li>分离x和y方向，计算平均池化；</li><li>拼接 + 卷积(通道下采样) + BN + 激活函数；</li><li>分离 + 分别卷积（通道上采样）+ 分别sigmod；</li><li>Re-weight；</li><li>思想：允许注意力模块捕捉到<strong>沿着一个空间方向的长期依赖关系，并保存沿着另一个空间方向的精确位置信息(通过通道来保另一个空间的精确位置信息)</strong>，这有助于网络更准确地定位感兴趣的目标。</li></ol><p><strong style=color:red>优化：</strong>无。</p></blockquote><hr><h2 id=背景知识 class=headerLink><a href=#%e8%83%8c%e6%99%af%e7%9f%a5%e8%af%86 class=header-mark></a>背景知识</h2><p>SENet：基于通道注意力机制，简单地squeeze每个2维特征图，进而有效地构建通道之间的相互依赖关系。r是用来控制SE block大小的缩减率。</p><p>CBAM：基于通道和空间信息的注意力机制。类似的，GENet、GALA、AA、TA，通过采用不同的空间注意力机制或设计高级注意力块，扩展了这一理念。</p><p>Non-local/Self-attention Network：</p><ol><li><p>根据各像素之间的相关性，对所有像素进行加权。权重越大，说明这个区域越重要。</p></li><li><p>NLNet、GCNet、A2Net、SCNet、GsopNet和CCNet，利用Non-local机制来捕获不同类型的空间信息。</p></li><li><p>由于Self-attention模块内部计算量大，常被用于大型模型中，不适用于Mobile Network。</p></li></ol><h2 id=原理方法 class=headerLink><a href=#%e5%8e%9f%e7%90%86%e6%96%b9%e6%b3%95 class=header-mark></a>原理方法</h2><h3 id=1coordinate-attention class=headerLink><a href=#1coordinate-attention class=header-mark></a>1、Coordinate Attention</h3><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220510101546974.png width=75%></div><p>全局池化：用于通道注意编码空间信息的全局编码，但由于它将全局空间信息压缩到通道描述符中，导致难以保存位置信息。</p><p>$$
z_{c}=\frac{1}{H \times W} \sum_{i=1}^{H} \sum_{j=1}^{W} x_{c}(i, j)
$$</p><p>Coordinate信息嵌入：使用尺寸为(H,1)或(1,W)的pooling kernel分别沿着水平坐标和垂直坐标对每个通道进行编码。两个空间方向聚合特征，得到一对方向感知的特征图。</p><p>$$
\begin{aligned} z_{c}^{h}(h) &=\frac{1}{W} \sum_{0 \leq i&lt;W} x_{c}(h, i) \ z_{c}^{w}(w) &=\frac{1}{H} \sum_{0 \leq j&lt;H} x_{c}(j, w) \end{aligned}
$$
特点：允许注意力模块捕捉到沿着一个空间方向的长期依赖关系，并保存沿着另一个空间方向的精确位置信息，这有助于网络更准确地定位感兴趣的目标。</p><h3 id=2coordinate-attention生成 class=headerLink><a href=#2coordinate-attention%e7%94%9f%e6%88%90 class=header-mark></a>2、Coordinate Attention生成</h3><p>设计原则：</p><ul><li>首先，对于Mobile环境中的应用来说，新的转换应该尽可能地简单。</li><li>其次，它可以充分利用捕获到的位置信息，使感兴趣的区域能够被准确地捕获。</li><li>最后，它还应该能够有效地捕捉通道间的关系。</li></ul><p>步骤：</p><ol><li>Concat + conv2d。</li></ol><p>$$
{\bf{f}} = \delta \left( {{F_{conv - 1 \times 1}}\left( {\left[ {{{\bf{z}}^h},{{\bf{z}}^w}} \right]} \right)} \right)
$$</p><ol start=2><li><p>BatchNorm + Non-linear。</p></li><li><p>Spilt+Conv2d+sigmoid。</p></li></ol><p>$$
{{\bf{g}}^h} = \sigma \left( {{F_{h - Conv1 \times 1}}\left( {{{\bf{f}}^h}} \right)} \right)
$$</p><p>$$
{{\bf{g}}^w} = \sigma \left( {{F_{w - Conv1 \times 1}}\left( {{{\bf{f}}^w}} \right)} \right)
$$</p><ol start=4><li>Re-weight。</li></ol><p>$$
{y_c}(i,j) = {x_c}(i,j) \times g_c^h(i) \times g_c^w(j)
$$</p><h3 id=3ca嵌入方式 class=headerLink><a href=#3ca%e5%b5%8c%e5%85%a5%e6%96%b9%e5%bc%8f class=header-mark></a>3、CA嵌入方式</h3><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220510101659847.png width=75%></div><h2 id=实验结果 class=headerLink><a href=#%e5%ae%9e%e9%aa%8c%e7%bb%93%e6%9e%9c class=header-mark></a>实验结果</h2><p>不同注意力机制对比实验结果：</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220510101751575.png width=75%></div><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220510101727043.png width=75%></div><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220510101821309.png width=75%></div><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220510101827964.png width=75%></div><p>可视化不同注意力机制实验结果：</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220510101926904.png width=75%></div><p>嵌入不同网络实验结果：</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220510101846144.png width=75%></div><p>目标检测实验结果：</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220510101959065.png width=75%></div><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220510102012308.png width=75%></div><p>图像分割实验结果：</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220510102030313.png width=75%></div><div align=center><img https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com/blog/image-20220510102039588.png width=75%></div><h2 id=参考文献 class=headerLink><a href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae class=header-mark></a>参考文献</h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p><a href=https://my.oschina.net/u/3776677/blog/4976696 target=_blank rel="noopener noreffer">陋室了凡-CVPR2021-即插即用 | Coordinate Attention详解与CA Block实现(文末获取论文原文)-oschina</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2022-05-10</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/>图像分类</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/201807-cbma/ class=prev rel=prev title="CBAM, Convolutional Block Attention Module"><i class="fas fa-angle-left fa-fw"></i>CBAM, Convolutional Block Attention Module</a>
<a href=/201905-efficientnet/ class=next rel=next title="EfficientNet, Rethinking Model Scaling for Convolutional Neural Networks">EfficientNet, Rethinking Model Scaling for Convolutional Neural Networks<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2022</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/about/ target=_blank rel="noopener noreferrer">Yangliuly1</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class=footer-line></div><div class=footer-line></div></div><script>"serviceWorker"in navigator&&(navigator.serviceWorker.register("/sw.min.js",{scope:"/"}).then(function(){}),navigator.serviceWorker.ready.then(function(){}))</script></footer></div><div id=fixed-buttons><a href=#back-to-top id=back-to-top-button class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><div class=assets><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/tablesort/tablesort.min.js></script><script type=text/javascript src=/lib/topbar/topbar.min.js></script><script type=text/javascript src=/lib/pjax/pjax.min.js></script><script type=text/javascript src=/js/theme.min.js defer></script></div><div class=pjax-assets><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:10},comment:{},data:{"desktop-header-typeit":"日落跌进迢迢星野,人间忽晚,山河已秋!","mobile-header-typeit":"日落跌进迢迢星野,人间忽晚,山河已秋!"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},table:{sort:!0},typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"desktop-header-typeit":["desktop-header-typeit"],"mobile-header-typeit":["mobile-header-typeit"]},duration:-1,speed:100}}</script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/typeit/typeit.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js defer></script><script type=text/javascript src=/lib/katex/auto-render.min.js defer></script><script type=text/javascript src=/lib/katex/copy-tex.min.js defer></script><script type=text/javascript src=/lib/katex/mhchem.min.js defer></script><script type=text/javascript src=/js/katex.min.js defer></script><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/copy-tex.min.css><noscript><link rel=stylesheet href=/lib/katex/copy-tex.min.css></noscript></div></body></html>