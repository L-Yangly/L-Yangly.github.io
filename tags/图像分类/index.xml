<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>图像分类 - Tag - Yang</title><link>https://Yangliuly1.github.io/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</link><description>图像分类 - Tag - Yang</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>yangliuly1993@gmail.com (Yangliuly1)</managingEditor><webMaster>yangliuly1993@gmail.com (Yangliuly1)</webMaster><lastBuildDate>Fri, 29 Apr 2022 20:00:49 +0800</lastBuildDate><atom:link href="https://Yangliuly1.github.io/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" rel="self" type="application/rss+xml"/><item><title>MobileNets, Efficient Convolutional Neural Networks for MobileVision Applications</title><link>https://Yangliuly1.github.io/201704-mobilenet-v1/</link><pubDate>Fri, 29 Apr 2022 20:00:49 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201704-mobilenet-v1/</guid><description>&lt;p>摘要：MobileNet V1是由google2016年提出，主要创新点在于深度可分离卷积。&lt;/p></description></item><item><title>Densely Connected Convolutional Networks</title><link>https://Yangliuly1.github.io/201608-densnet/</link><pubDate>Thu, 28 Apr 2022 23:25:46 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201608-densnet/</guid><description>&lt;p>摘要：DenseNet脱离了加深网络层数(ResNet)和加宽网络结构(Inception)来提升网络性能的定式思维，从特征的角度考虑，通过特征重用和旁路(Bypass)设置,既大幅度减少了网络的参数量，又在一定程度上缓解了gradient vanishing问题的产生。结合信息流和特征复用的假设，DenseNet当之无愧成为2017年计算机视觉顶会的年度最佳论文。&lt;/p></description></item><item><title>Xception, Deep Learning with Depthwise Separable Convolutions</title><link>https://Yangliuly1.github.io/201608-xception/</link><pubDate>Thu, 28 Apr 2022 21:57:27 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201608-xception/</guid><description>&lt;p>摘要：基于Inception v3是假设出发，即解耦通道相关性和空间相关性，进行简化，推导出深度可分离卷积，构建Inception v4网络。&lt;/p></description></item><item><title>Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</title><link>https://Yangliuly1.github.io/201602-inception-v4/</link><pubDate>Wed, 27 Apr 2022 16:34:57 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201602-inception-v4/</guid><description>&lt;p>摘要：Incetpion网络趋于深度化，提高网络容量的同时还能保证计算复杂性不至于过高，而ResNet网络解决了在网络深度化时准确率下降的问题，所以很自然地就想到将这两者结合起来，组成Inception-ResNet。&lt;/p></description></item><item><title>Rethinking the Inception Architecture for Computer</title><link>https://Yangliuly1.github.io/201512-inception-v3/</link><pubDate>Wed, 27 Apr 2022 14:59:17 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201512-inception-v3/</guid><description>&lt;p>摘要：针对计算效率方面的作用，提出了分解卷积等思想。&lt;/p></description></item><item><title>Batch Normalization, Accelerating Deep Network Training by Reducing Internal Covariate Shift</title><link>https://Yangliuly1.github.io/201504-inception-v2/</link><pubDate>Wed, 27 Apr 2022 10:18:50 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201504-inception-v2/</guid><description>&lt;p>摘要：BN归一化，加速收敛，防止梯度消失。&lt;/p></description></item><item><title>Going deeper with convolutions</title><link>https://Yangliuly1.github.io/201409-googlenet/</link><pubDate>Tue, 26 Apr 2022 22:46:53 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201409-googlenet/</guid><description>&lt;p>摘要：针对网络越来越大的问题，GooLeNet提出了将全连接的结构变为稀疏的全连接结构。然而，运算设备在处理不均匀的稀疏数据时运算效率很低。GoogLeNet将稀疏矩阵聚合成稠密矩阵，构建Inception结构解决稀疏运算效率问题。&lt;/p></description></item><item><title>Gradient-Based Learning Applied to Document Recognition</title><link>https://Yangliuly1.github.io/199811-lenet/</link><pubDate>Mon, 25 Apr 2022 14:01:24 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/199811-lenet/</guid><description>&lt;p>摘要：LeNet-5 是一个专为手写数字识别而设计的最经典的卷积神经网络，被誉为早期卷积神经网络中最有代表性的实验系统之一。&lt;/p></description></item><item><title>Very Deep Convolutional Networks for Large-Scale Image Recognition</title><link>https://Yangliuly1.github.io/201409-vgg/</link><pubDate>Mon, 25 Apr 2022 13:22:58 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201409-vgg/</guid><description>&lt;p>摘要：VGG 小卷积替换大卷积，减少网络参数，提高网络深度。&lt;/p></description></item><item><title>Aggregated Residual Transformations for Deep Neural Networks</title><link>https://Yangliuly1.github.io/201611-resnext/</link><pubDate>Mon, 25 Apr 2022 09:24:21 +0800</pubDate><author><name>Yangliuly1</name></author><guid>https://Yangliuly1.github.io/201611-resnext/</guid><description>&lt;p>摘要：ResNeXt，借鉴VGG、ResNet和Inception的思想组合一下，核心是分组卷积。&lt;/p></description></item></channel></rss>