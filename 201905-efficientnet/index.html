<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title class=pjax-title>EfficientNet, Rethinking Model Scaling for Convolutional Neural Networks - Yang</title><meta name=Description content><meta property="og:title" content="EfficientNet, Rethinking Model Scaling for Convolutional Neural Networks"><meta property="og:description" content="摘要：EfficientNet提出了一种新的模型缩放方法，它使用一个简单而高效的复合系数来从depth, width, resolution 三个维度放大网络，不会像传统的方法那样任意缩放网络的维度，基于神经结构搜索技术可以获得最优的一组参数(复合系数)。"><meta property="og:type" content="article"><meta property="og:url" content="https://Yangliuly1.github.io/201905-efficientnet/"><meta property="og:image" content="https://Yangliuly1.github.io/images/avatar.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-05-11T18:57:56+08:00"><meta property="article:modified_time" content="2022-05-11T18:57:56+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://Yangliuly1.github.io/images/avatar.png"><meta name=twitter:title content="EfficientNet, Rethinking Model Scaling for Convolutional Neural Networks"><meta name=twitter:description content="摘要：EfficientNet提出了一种新的模型缩放方法，它使用一个简单而高效的复合系数来从depth, width, resolution 三个维度放大网络，不会像传统的方法那样任意缩放网络的维度，基于神经结构搜索技术可以获得最优的一组参数(复合系数)。"><meta name=application-name content="Yang"><meta name=apple-mobile-web-app-title content="Yang"><meta name=theme-color content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://Yangliuly1.github.io/201905-efficientnet/><link rel=prev href=https://Yangliuly1.github.io/202103-ca/><link rel=next href=https://Yangliuly1.github.io/201507-yolov1/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/fontawesome-free/all.min.css><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/animate/animate.min.css><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"EfficientNet, Rethinking Model Scaling for Convolutional Neural Networks","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/Yangliuly1.github.io\/201905-efficientnet\/"},"genre":"posts","keywords":"图像分类","wordcount":265,"url":"https:\/\/Yangliuly1.github.io\/201905-efficientnet\/","datePublished":"2022-05-11T18:57:56+08:00","dateModified":"2022-05-11T18:57:56+08:00","publisher":{"@type":"Organization","name":"Yangliuly1"},"author":{"@type":"Person","name":"Yangliuly1"},"description":""}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>function setTheme(e){document.body.setAttribute("theme",e),document.documentElement.style.setProperty("color-scheme",e==="light"?"light":"dark")}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(e){const t=document.getElementsByTagName("meta");for(let n=0;n<t.length;n++)if(t[n].getAttribute("name")===e)return t[n];return""}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"||e==="black"?setTheme(e):setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")}else"auto"==="light"||"auto"==="dark"||"auto"==="black"?(setTheme("auto"),saveTheme("auto")):(saveTheme("auto"),setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"));let metaColors={light:"#f8f8f8",dark:"#252627",black:"#000000"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")]</script><div id=back-to-top></div><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=Yang><span class=header-title-pre><i class='far fa-edit fa-fw'></i></span><span id=desktop-header-typeit class=typeit></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/about/>关于 </a><a class=menu-item href=https://github.com/Yangliuly1 title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i> </a><span class="menu-item delimiter"></span><a href=# onclick=return!1 class="menu-item theme-select" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
<select class=color-theme-select id=theme-select-desktop title="Switch Theme"><option value=light>Light</option><option value=dark>Dark</option><option value=black>Black</option><option value=auto>Auto</option></select></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=Yang><span class=header-title-pre><i class='far fa-edit fa-fw'></i></span><span id=mobile-header-typeit class=typeit></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/about/ title>关于</a><a class=menu-item href=https://github.com/Yangliuly1 title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i></a><a href=# onclick=return!1 class="menu-item theme-select" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
<select class=color-theme-select id=theme-select-mobile title="Switch Theme"><option value=light>Light</option><option value=dark>Dark</option><option value=black>Black</option><option value=auto>Auto</option></select></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class="toc-content always-active" id=toc-content-auto><nav id=TableOfContents><ul><li><a href=#文献信息>文献信息</a></li><li><a href=#个人理解>个人理解</a></li><li><a href=#背景知识>背景知识</a></li><li><a href=#原理方法>原理方法</a><ul><li><a href=#1网络参数讨论>1、网络参数讨论</a></li><li><a href=#2复合模型扩张方法>2、复合模型扩张方法</a></li></ul></li><li><a href=#训练测试>训练测试</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></div><script>document.getElementsByTagName("main")[0].setAttribute("pageStyle","normal")</script><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","true")</script><article class="page single"><h1 class="single-title animate__animated animate__flipInX">EfficientNet, Rethinking Model Scaling for Convolutional Neural Networks</h1><div class=post-meta><div class=post-meta-line><span class=post-author><i class="author fas fa-user-circle fa-fw"></i><a href=/about/ title=Author rel=author class=author>Yangliuly1</a>
</span>&nbsp;<span class=post-category>included in </span>&nbsp;<span class=post-category>category <a href=/categories/%E4%B8%93%E4%B8%9A%E8%AE%BA%E6%96%87/><i class="far fa-folder fa-fw"></i>专业论文</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2022-05-11>2022-05-11</time>&nbsp;<i class="far fa-edit fa-fw"></i>&nbsp;<time datetime=2022-05-11>2022-05-11</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;265 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;2 minutes&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#文献信息>文献信息</a></li><li><a href=#个人理解>个人理解</a></li><li><a href=#背景知识>背景知识</a></li><li><a href=#原理方法>原理方法</a><ul><li><a href=#1网络参数讨论>1、网络参数讨论</a></li><li><a href=#2复合模型扩张方法>2、复合模型扩张方法</a></li></ul></li><li><a href=#训练测试>训练测试</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></div><div class=content id=content><p>摘要：EfficientNet提出了一种新的模型缩放方法，它使用一个简单而高效的复合系数来从depth, width, resolution 三个维度放大网络，不会像传统的方法那样任意缩放网络的维度，基于神经结构搜索技术可以获得最优的一组参数(复合系数)。</p><h1 id=efficientnet-rethinking-model-scaling-for-convolutional-neural-networks class=headerLink><a href=#efficientnet-rethinking-model-scaling-for-convolutional-neural-networks class=header-mark></a>EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</h1><h2 id=文献信息 class=headerLink><a href=#%e6%96%87%e7%8c%ae%e4%bf%a1%e6%81%af class=header-mark></a>文献信息</h2><table><thead><tr><th>信息</th><th>内容</th></tr></thead><tbody><tr><td>日期</td><td>xx, xx xxxx</td></tr><tr><td>作者</td><td>Mingxing Tan et al.</td></tr><tr><td>机构</td><td>xxxxxxxx</td></tr><tr><td>来源</td><td>期刊杂志</td></tr><tr><td>链接</td><td><a href=https://arxiv.org/abs/1905.11946 target=_blank rel="noopener noreffer">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a></td></tr><tr><td>代码</td><td><a href rel>Code</a></td></tr></tbody></table><h2 id=个人理解 class=headerLink><a href=#%e4%b8%aa%e4%ba%ba%e7%90%86%e8%a7%a3 class=header-mark></a>个人理解</h2><blockquote><p><strong style=color:red>问题:</strong> 文章为了解决什么问题；</p><p><strong style=color:red>方法:</strong> 文章提出了什么方法和技术；</p><p><strong style=color:red>结论:</strong> 文章结论即 数据集 + 评价 指标；</p><p><strong style=color:red>理解:</strong> 论文读完的感受与体会，比如该方法借鉴了什么思想，方法是不是新颖，实验怎么做的，讨论的变量是什么，还有其他值得读的文献。</p><p><strong style=color:red>优化：</strong>还有什么值得改进与优化的。</p></blockquote><hr><h2 id=背景知识 class=headerLink><a href=#%e8%83%8c%e6%99%af%e7%9f%a5%e8%af%86 class=header-mark></a>背景知识</h2><p>卷积神经网络（ConvNets）通常是在固定的资源预算下发展起来的，如果有更多的资源可用的话，则会扩大规模以获得更好的精度，比如可以提高网络深度(depth)、网络宽度(width)和输入图像分辨率 (resolution)大小。但是通过人工去调整 depth, width, resolution 的放大或缩小的很困难的，在计算量受限时有放大哪个缩小哪个，这些都是很难去确定的，换句话说，这样的组合空间太大，人力无法穷举。</p><h2 id=原理方法 class=headerLink><a href=#%e5%8e%9f%e7%90%86%e6%96%b9%e6%b3%95 class=header-mark></a>原理方法</h2><h3 id=1网络参数讨论 class=headerLink><a href=#1%e7%bd%91%e7%bb%9c%e5%8f%82%e6%95%b0%e8%ae%a8%e8%ae%ba class=header-mark></a>1、网络参数讨论</h3><p>问题定义：我们将整个卷积网络称为 N，它的第 i 个卷积层可以表示为：$ Y_{i}=F_{i}\left(X_{i}\right)$, $X_{i} $ 代表输入张量,$ \quad Y_{i} $ 代表输出张量。整个卷积网络由 k 个卷积层组成，可以表示为：</p><p>$$
\mathcal{N}=\mathcal{F}<em>{k} \odot \ldots \odot \mathcal{F}</em>{2} \odot \mathcal{F}<em>{1}\left(X</em>{1}\right)=\odot_{j=1 \ldots k} \mathcal{F}<em>{j}\left(X</em>{1}\right)
$$</p><p>但是在实际中，通常会将多个结构相同的卷积层称为一个stage，例如ResNet有5个stage，每个stage中的卷积层结构相同(除了第一层为降采样层)，以 stage 为单位可以将卷积网络 N 表示为：</p><p>$$
\mathcal{N}=\bigoplus_{i=1 \ldots s} \mathcal{F}<em>{i}^{L</em>{i}}\left(X_{\left\langle H_{i}, W_{i}, C_{i}\right\rangle}\right)
$$</p><p>其中，$ &lt;H_{I}, W_{I}, C_{i}> $代表第i层的输入张量的维度（为了方便叙述忽略 batch 这个维度），下标 i(从 1 到 s) 表示的是 stage 的序号，$ F_{i}^{L_{i}} $表示第 i 个 stage ，它由卷积层$F_i$重复$L_i$次构成。</p><p>与通常的ConvNet设计不同，通常的ConvNet设计主要关注寻找最佳的网络层$F_i$, 模型缩放尝试扩展网络长度（$L_i$）、宽度（$C_i$）和分辨率（$(H_i,W_i)$），而不改变基线网络中预定义的$F_i$（个人在这里的理解是指kernel size等每一个层内的参数，因为模型缩放只对depth, width, resolution进行组合调整，不对每一个层内具体的方式做改变）。</p><p>所以，优化目标就是在资源有限的情况下，要最大化 Accuracy, 优化目标的公式表达如下：</p><p>$$
\max_{d, w, r} \text { Accuracy }(\mathcal{N}(d, w, r)) \
\text { s.t. } \mathcal{N}(d, w, r)=\underset{i=1 \ldots s}{\bigoplus} \hat{\mathcal{F}}<em>{i}^{d \cdot \hat{L}</em>{i}}\left(X_{\left\langle r \cdot \hat{H}<em>{i}, r \cdot \hat{W}</em>{i}, w \cdot \hat{C}_{i}\right\rangle}\right) \
\operatorname{Memory}(\mathcal{N}) \leq \text { target_memory } \
\operatorname{FLOPS}(\mathcal{N}) \leq \text { target_flops } \
$$</p><p>作者发现，更大的网络具有更大的宽度、深度或分辨率，往往可以获得更高的精度，但精度增益在达到80%后会迅速饱和，这表明了只对单一维度进行扩张的局限性，实验结果如下：</p><p>作者指出，模型扩张的各个维度之间并不是完全独立的，比如说，对于更大的分辨率图像，应该使用更深、更宽的网络，这就意味着需要平衡各个扩张维度，而不是在单一维度张扩张。</p><p>直线上的每个点表示具有不同宽度系数（w）的模型：第一个基线网络（d=1.0，r=1.0）有18个卷积层，分辨率224x224，而最后一个基线（d=2.0，r=1.3）有36个卷积层，分辨率299x299。</p><p>这个图说明了一个问题，为了追求更好的精度和效率，在ConvNet缩放过程中平衡网络宽度、深度和分辨率的所有维度是至关重要的。</p><h3 id=2复合模型扩张方法 class=headerLink><a href=#2%e5%a4%8d%e5%90%88%e6%a8%a1%e5%9e%8b%e6%89%a9%e5%bc%a0%e6%96%b9%e6%b3%95 class=header-mark></a>2、复合模型扩张方法</h3><p>本文提出了复合扩张方法，组合深度、宽度和分辨率，即$(\alpha, \beta, \gamma)$是求解的一组参数，带约束的最优参数求解。$(\alpha, \beta, \gamma)$分别衡量着depth, width和resolution的比重，其中 $\beta,\gamma$在约束上会有平方，是因为增加宽度或分辨率两倍，对应计算量是增加四倍，但是增加深度两倍，其计算量只会增加两倍。</p><p>$$
depth: d=\alpha^{\phi} \
width: w=\beta^{\phi} \
resolution: r=\gamma^{\phi} \
s.t. \alpha \cdot \beta^{2} \cdot \gamma^{2} \approx 2 \
\alpha \geq 1, \beta \geq 1, \gamma \geq 1
$$</p><p>迭代求解方式：</p><ol><li>固定公式中的$φ=1$，然后通过网格搜索（grid search）得出最优的α、β、γ，得出最基本模型EfficientNet-B0;</li><li>固定$α, β, γ$的值，使用不同的$φ$，得到EfficientNet-B1, &mldr;, EfficientNet-B7;</li></ol><p>$φ$的大小对应着消耗资源的大小，相当于：</p><ol><li>当φ=1时，得出了一个最小的最优基础模型；</li><li>增大φ时，相当于对基模型三个维度同时扩展，模型变大，性能也会提升，资源消耗也变大;</li></ol><p>对于神经网络搜索，作者使用了和 <code>MnasNet: Platform-awareneural architecture search for mobile</code> 一样的搜索空间和优化目标。</p><p>第一处区别是在最开始降采样没有采用maxpooling，而是换成了stride为2的conv。。猜测是为了减少信息丢失，尤其是对小模型来说，前期的底层特征提取更重要。</p><p>第二处区别是第一次降采样后的channel反而减少了，这个我没搞懂。。。。</p><p>第三处区别是有很多stage都采用了5x5的conv。。。这是因为对于depthwise separable conv来说，5x5的计算量要比两个3x3的计算量要小。。（坊间传闻large kernel is all your need. 233333）</p><p>[公式]</p><p>其中输入特征图尺寸为(H, W, M)，输出特征图尺寸为(H, W, N)。</p><p>第四处区别是降采样后的特征图尺寸减半，但是channel没有扩大两倍。第6个stage特征图尺寸没变，但是channel也扩大了。。这些可能都是手工设计很难搞定的。。。我能想到的解释是，MnasNet在搜网络结构的时候带上了运算量的约束，可以理解成网络在训练的时候就考虑了pruing(裁枝)，因此才会出现一些不规则的channel数，同时这个带来另外的一个好处就是，网络可以更好的训练更有意义的权重，因此这些搜出来的网络结构的上限更高。</p><p>MBConv</p><p>，发现实际部署算法的时候往往不太追求极限精度，反而更多的要考虑模型大小和资源消耗</p><p>而EfficientNet用复合scaling的方法告诉你，用他这种方法，从 精度低的小网络 放缩到 精度高的大网络 ，精度和资源消耗能呈现出正相关的效果</p><p><strong>small</strong> grid search</p><h2 id=训练测试 class=headerLink><a href=#%e8%ae%ad%e7%bb%83%e6%b5%8b%e8%af%95 class=header-mark></a>训练测试</h2><h2 id=参考文献 class=headerLink><a href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae class=header-mark></a>参考文献</h2></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2022-05-11</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/>图像分类</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/202103-ca/ class=prev rel=prev title="Coordinate Attention for Efficient Mobile Network Design"><i class="fas fa-angle-left fa-fw"></i>Coordinate Attention for Efficient Mobile Network Design</a>
<a href=/201507-yolov1/ class=next rel=next title="You Only Look Once - Unified, Real-Time Object Detection">You Only Look Once - Unified, Real-Time Object Detection<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2022</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/about/ target=_blank rel="noopener noreferrer">Yangliuly1</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class=footer-line></div><div class=footer-line></div></div><script>"serviceWorker"in navigator&&(navigator.serviceWorker.register("/sw.min.js",{scope:"/"}).then(function(){}),navigator.serviceWorker.ready.then(function(){}))</script></footer></div><div id=fixed-buttons><a href=#back-to-top id=back-to-top-button class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><div class=assets><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/tablesort/tablesort.min.js></script><script type=text/javascript src=/lib/topbar/topbar.min.js></script><script type=text/javascript src=/lib/pjax/pjax.min.js></script><script type=text/javascript src=/js/theme.min.js defer></script></div><div class=pjax-assets><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:10},comment:{},data:{"desktop-header-typeit":"日落跌进迢迢星野,人间忽晚,山河已秋!","mobile-header-typeit":"日落跌进迢迢星野,人间忽晚,山河已秋!"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},table:{sort:!0},typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"desktop-header-typeit":["desktop-header-typeit"],"mobile-header-typeit":["mobile-header-typeit"]},duration:-1,speed:100}}</script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/typeit/typeit.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js defer></script><script type=text/javascript src=/lib/katex/auto-render.min.js defer></script><script type=text/javascript src=/lib/katex/copy-tex.min.js defer></script><script type=text/javascript src=/lib/katex/mhchem.min.js defer></script><script type=text/javascript src=/js/katex.min.js defer></script><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/copy-tex.min.css><noscript><link rel=stylesheet href=/lib/katex/copy-tex.min.css></noscript></div></body></html>