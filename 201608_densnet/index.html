<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title class=pjax-title>Densely Connected Convolutional Networks - Yang</title><meta name=Description content><meta property="og:title" content="Densely Connected Convolutional Networks"><meta property="og:description" content="摘要：DenseNet脱离了加深网络层数(ResNet)和加宽网络结构(Inception)来提升网络性能的定式思维，从特征的角度考虑，通过特征重用和旁路(Bypass)设置,既大幅度减少了网络的参数量，又在一定程度上缓解了gradient vanishing问题的产生。结合信息流和特征复用的假设，DenseNet当之无愧成为2017年计算机视觉顶会的年度最佳论文。"><meta property="og:type" content="article"><meta property="og:url" content="https://Yangliuly1.github.io/201608_densnet/"><meta property="og:image" content="https://Yangliuly1.github.io/images/avatar.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-04-28T23:25:46+08:00"><meta property="article:modified_time" content="2022-04-28T23:25:46+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://Yangliuly1.github.io/images/avatar.png"><meta name=twitter:title content="Densely Connected Convolutional Networks"><meta name=twitter:description content="摘要：DenseNet脱离了加深网络层数(ResNet)和加宽网络结构(Inception)来提升网络性能的定式思维，从特征的角度考虑，通过特征重用和旁路(Bypass)设置,既大幅度减少了网络的参数量，又在一定程度上缓解了gradient vanishing问题的产生。结合信息流和特征复用的假设，DenseNet当之无愧成为2017年计算机视觉顶会的年度最佳论文。"><meta name=application-name content="Yang"><meta name=apple-mobile-web-app-title content="Yang"><meta name=theme-color content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://Yangliuly1.github.io/201608_densnet/><link rel=prev href=https://Yangliuly1.github.io/201608_xception/><link rel=next href=https://Yangliuly1.github.io/201704_mobilenet-v1/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/fontawesome-free/all.min.css><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/animate/animate.min.css><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Densely Connected Convolutional Networks","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/Yangliuly1.github.io\/201608_densnet\/"},"genre":"posts","keywords":"图像分类","wordcount":148,"url":"https:\/\/Yangliuly1.github.io\/201608_densnet\/","datePublished":"2022-04-28T23:25:46+08:00","dateModified":"2022-04-28T23:25:46+08:00","publisher":{"@type":"Organization","name":"Yangliuly1"},"author":{"@type":"Person","name":"Yangliuly1"},"description":""}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>function setTheme(e){document.body.setAttribute("theme",e),document.documentElement.style.setProperty("color-scheme",e==="light"?"light":"dark")}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(e){const t=document.getElementsByTagName("meta");for(let n=0;n<t.length;n++)if(t[n].getAttribute("name")===e)return t[n];return""}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"||e==="black"?setTheme(e):setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")}else"auto"==="light"||"auto"==="dark"||"auto"==="black"?(setTheme("auto"),saveTheme("auto")):(saveTheme("auto"),setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"));let metaColors={light:"#f8f8f8",dark:"#252627",black:"#000000"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")]</script><div id=back-to-top></div><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=Yang><span class=header-title-pre><i class='far fa-edit fa-fw'></i></span><span id=desktop-header-typeit class=typeit></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/about/>关于 </a><a class=menu-item href=https://github.com/Yangliuly1 title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i> </a><span class="menu-item delimiter"></span><a href=# onclick=return!1 class="menu-item theme-select" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
<select class=color-theme-select id=theme-select-desktop title="Switch Theme"><option value=light>Light</option><option value=dark>Dark</option><option value=black>Black</option><option value=auto>Auto</option></select></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=Yang><span class=header-title-pre><i class='far fa-edit fa-fw'></i></span><span id=mobile-header-typeit class=typeit></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/about/ title>关于</a><a class=menu-item href=https://github.com/Yangliuly1 title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i></a><a href=# onclick=return!1 class="menu-item theme-select" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
<select class=color-theme-select id=theme-select-mobile title="Switch Theme"><option value=light>Light</option><option value=dark>Dark</option><option value=black>Black</option><option value=auto>Auto</option></select></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class="toc-content always-active" id=toc-content-auto><nav id=TableOfContents><ul><li><a href=#文献信息>文献信息</a></li><li><a href=#个人理解>个人理解</a></li><li><a href=#背景知识>背景知识</a></li><li><a href=#原理方法>原理方法</a><ul><li><a href=#1-密集连接>1、 密集连接</a></li><li><a href=#2池化层>2、池化层</a></li><li><a href=#3-增长率-growth-rate>3、 增长率 Growth rate</a></li><li><a href=#4瓶颈层-bottleneck-layers>4、瓶颈层 Bottleneck Layers</a></li><li><a href=#5压缩-compression>5、压缩 Compression：</a></li></ul></li><li><a href=#实验结果>实验结果</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></div><script>document.getElementsByTagName("main")[0].setAttribute("pageStyle","normal")</script><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","true")</script><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Densely Connected Convolutional Networks</h1><div class=post-meta><div class=post-meta-line><span class=post-author><i class="author fas fa-user-circle fa-fw"></i><a href=/about/ title=Author rel=author class=author>Yangliuly1</a>
</span>&nbsp;<span class=post-category>included in </span>&nbsp;<span class=post-category>category <a href=/categories/%E4%B8%93%E4%B8%9A%E8%AE%BA%E6%96%87/><i class="far fa-folder fa-fw"></i>专业论文</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2022-04-28>2022-04-28</time>&nbsp;<i class="far fa-edit fa-fw"></i>&nbsp;<time datetime=2022-04-28>2022-04-28</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;148 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;One minute&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#文献信息>文献信息</a></li><li><a href=#个人理解>个人理解</a></li><li><a href=#背景知识>背景知识</a></li><li><a href=#原理方法>原理方法</a><ul><li><a href=#1-密集连接>1、 密集连接</a></li><li><a href=#2池化层>2、池化层</a></li><li><a href=#3-增长率-growth-rate>3、 增长率 Growth rate</a></li><li><a href=#4瓶颈层-bottleneck-layers>4、瓶颈层 Bottleneck Layers</a></li><li><a href=#5压缩-compression>5、压缩 Compression：</a></li></ul></li><li><a href=#实验结果>实验结果</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></div><div class=content id=content><p>摘要：DenseNet脱离了加深网络层数(ResNet)和加宽网络结构(Inception)来提升网络性能的定式思维，从特征的角度考虑，通过特征重用和旁路(Bypass)设置,既大幅度减少了网络的参数量，又在一定程度上缓解了gradient vanishing问题的产生。结合信息流和特征复用的假设，DenseNet当之无愧成为2017年计算机视觉顶会的年度最佳论文。</p><h2 id=文献信息 class=headerLink><a href=#%e6%96%87%e7%8c%ae%e4%bf%a1%e6%81%af class=header-mark></a>文献信息</h2><table><thead><tr><th>信息</th><th>内容</th></tr></thead><tbody><tr><td>日期</td><td>2016.08</td></tr><tr><td>作者</td><td>Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger.</td></tr><tr><td>机构</td><td>Cornell University, Tsinghua University, Facebook AI Research, Cornell University</td></tr><tr><td>来源</td><td>CVPR 2017 年度最佳论文</td></tr><tr><td>链接</td><td><a href=https://arxiv.org/abs/1608.06993 target=_blank rel="noopener noreffer">Densely Connected Convolutional Networks</a></td></tr><tr><td>代码</td><td><a href=https://github.com/liuzhuang13/DenseNet target=_blank rel="noopener noreffer">liuzhuang13/DenseNet</a></td></tr></tbody></table><h2 id=个人理解 class=headerLink><a href=#%e4%b8%aa%e4%ba%ba%e7%90%86%e8%a7%a3 class=header-mark></a>个人理解</h2><blockquote><p><strong style=color:red>问题:</strong> 文章为了解决梯度消失和参数问题；</p><p><strong style=color:red>方法:</strong> 文章提出了信息流和特征复用思想，即cat而不是add，保证信息流的流通，特征复用是前面所有层cat，这样可用用少量的通道组成大通道数；</p><p><strong style=color:red>结论:</strong> CIFAR-10、CIFAR-100、SVHN和ImageNet 达到SOTA；</p><p><strong style=color:red>理解:</strong></p><ol><li>信息流，更强的梯度流动：DenseNet可以说是一种隐式的强监督模式，因为每一层都建立起了与前面层的连接，误差信号可以很容易地传播到较早的层，所以较早的层可以从最终分类层获得直接监管。</li><li>参数更少计算效率更高：在ResNet中，参数量与$C \times C$成正比，而在DenseNet中参数量与$l \times k \times k $成正比，因为k远小于C，所以DenseNet的参数量小得多。</li><li>保存了低维度的特征：在标准的卷积网络中，最终输出只会利用提取最高层次的特征。而在DenseNet中，它使用了不同层次的特征,它倾向于给出更平滑的决策边界。这也解释了为什么训练数据不足时DenseNet表现依旧良好。</li></ol><p><strong style=color:red>优化：</strong>但是个人感觉DensNet没有ResNet用得广？不知道什么原因。</p></blockquote><hr><h2 id=背景知识 class=headerLink><a href=#%e8%83%8c%e6%99%af%e7%9f%a5%e8%af%86 class=header-mark></a>背景知识</h2><p>随着CNN网络层数的不断增加，gradient vanishing和model degradation问题出现在了人们面前，BatchNormalization的广泛使用在一定程度上缓解了gradient vanishing的问题，而ResNet和Highway Networks通过构造恒等映射设置旁路，进一步减少了gradient vanishing和model degradation的产生。Fractal Nets通过将不同深度的网络并行化,在获得了深度的同时保证了梯度的传播，随机深度网络通过对网络中一些层进行失活,既证明了ResNet深度的冗余性，又缓解了上述问题的产生。虽然这些不同的网络框架通过不同的实现加深的网络层数，但是他们都包含了相同的核心思想，既将特征图进行跨网络层的连接。</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com//images/20220706213841.png width=75%></div><p>DenseNet作为另一种拥有较深层数的卷积神经网络，具有如下优点:</p><p>(1) 相比ResNet拥有更少的参数数量。</p><p>(2) 旁路加强了特征的重用。</p><p>(3) 网络更易于训练，并具有一定的正则效果。</p><p>(4) 缓解了gradient vanishing和model degradation的问题。</p><p>何恺明先生在提出ResNet时做出了这样的假设：若某一较深的网络多出另一较浅网络的若干层有能力学习到恒等映射，那么这一较深网络训练得到的模型性能一定不会弱于该浅层网络。通俗的说就是如果对某一网络中增添一些可以学到恒等映射的层组成新的网路，那么最差的结果也是新网络中的这些层在训练后成为恒等映射而不会影响原网络的性能。</p><p>同样DenseNet在提出时也做过假设:与其多次学习冗余的特征,特征复用是一种更好的特征提取方式。</p><h2 id=原理方法 class=headerLink><a href=#%e5%8e%9f%e7%90%86%e6%96%b9%e6%b3%95 class=header-mark></a>原理方法</h2><p>假设输入为一个图片$X_0$ , 经过一个L层的神经网络, 其中第i层的非线性变换记为$H_i(<em>)$, $H_i(</em>)$可以是多种函数操作的累加如BN、ReLU、Pooling或Conv等. 第i层的特征输出记作$X_i$。</p><p>ResNet：传统卷积前馈神经网络将第i层的输出$X_i$作为i+1层的输入,可以写作$X_i = H_i(X_{i-1})$. ResNet增加了旁路连接,可以写作</p><p>$$
X_i = H_i(X_{i-1}) + X_{i-1}
$$</p><p>ResNet的一个最主要的优势便是梯度可以流经恒等函数来到达靠前的层。但恒等映射和非线性变换输出的叠加方式是相加, 这在一定程度上破坏了网络中的信息流。</p><h3 id=1-密集连接 class=headerLink><a href=#1-%e5%af%86%e9%9b%86%e8%bf%9e%e6%8e%a5 class=header-mark></a>1、 密集连接</h3><p>为了进一步优化信息流的传播，DenseNet提出了图示的网络结构，</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com//images/20220706213842.png width=75%></div><p>如图所示，第i层的输入不仅与i-1层的输出相关，还有所有之前层的输出有关。记作:</p><p>$$
X_l = H_l ([X_0, X_1, &mldr;, X_{l-1}])
$$</p><p>其中[]代表concatenation(拼接),既将$X_1$ 到$X_{l-1}$层的所有输出特征图按通道组合在一起。这里所用到的非线性变换H为<code>BN+ReLU+ Conv(3×3)</code>的组合。</p><h3 id=2池化层 class=headerLink><a href=#2%e6%b1%a0%e5%8c%96%e5%b1%82 class=header-mark></a>2、池化层</h3><p>在DenseNet中需要对不同层的特征图进行cat操作，所以需要不同层的特征图保持相同的特征尺度，这就限制了网络中下采样的实现。为了使用下采样，作者将DenseNet分为多个Denseblock:</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com//images/20220706213842.png width=75%></div><p>在同一个Denseblock中要求特征尺度保持相同大小，在不同Denseblock之间设置过渡层（transitionlayer）实现Downsampling, 在作者的实验中过渡层（transitionlayer）由<code>BN + Conv(1×1) ＋2×2 average-pooling</code>组成。</p><h3 id=3-增长率-growth-rate class=headerLink><a href=#3-%e5%a2%9e%e9%95%bf%e7%8e%87-growth-rate class=header-mark></a>3、 增长率 Growth rate</h3><p>在Denseblock中，假设每一个非线性变换H的输出为K个特征图, 那么第i层网络的输入便为$K_0 + (i-1)×K$, 但DenseNet不同点是可以接受较少的特征图数量作为网络层的841输出，</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com//images/20220706213843.png width=75%></div><p>原因就是在同一个Denseblock中的每一层都与之前所有层相关联，如果把feature看作是一个Denseblock的全局状态，那么每一层的训练目标便是通过现有的全局状态，判断需要添加给全局状态的更新值。因而每个网络层输出的特征图数量K又称为Growth rate，同样决定着每一层需要给全局状态更新的信息的多少。在作者的实验中只需要较小的K便足以实现state-of-art的性能。</p><h3 id=4瓶颈层-bottleneck-layers class=headerLink><a href=#4%e7%93%b6%e9%a2%88%e5%b1%82-bottleneck-layers class=header-mark></a>4、瓶颈层 Bottleneck Layers</h3><p>虽然DenseNet接受较少的k，即特征图的数量作为输出，但由于不同层特征图之间由cat操作组合在一起，最终仍然会是特征图的通道较大而成为网络的负担。作者使用<code>1×1 Conv(Bottleneck)</code>作为特征降维的方法来降低通道数量，以提高计算效率。经过改善后的非线性变换变为<code>BN-ReLU-Conv(1×1)-BN-ReLU-Conv(3×3)</code>,使用Bottleneck layers的DenseNet被作者称为DenseNet-B。在实验中，作者使用1×1卷积生成通道数量为4k的特征图。</p><h3 id=5压缩-compression class=headerLink><a href=#5%e5%8e%8b%e7%bc%a9-compression class=header-mark></a>5、压缩 Compression：</h3><p>为了进一步优化模型的简洁性，同样可以在过渡层transition layer中降低特征图的数量。若一个Denseblock中包含m个特征图s，那么使其输出连接的transition layer层生成⌊θm⌋个输出特征图。其中θ为Compression factor, 当θ=1时，过渡层transition layer将保留原feature维度不变。</p><p>作者将使用compression且θ=0.5的DenseNet命名为DenseNet-C, 将使用Bottleneck和compression且θ=0.5的DenseNet命名为DenseNet-BC。</p><h2 id=实验结果 class=headerLink><a href=#%e5%ae%9e%e9%aa%8c%e7%bb%93%e6%9e%9c class=header-mark></a>实验结果</h2><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com//images/20220706213844.png width=75%></div><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com//images/20220706213844.png width=75%></div><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com//images/20220706213845.png width=75%></div><h2 id=参考文献 class=headerLink><a href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae class=header-mark></a>参考文献</h2></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2022-04-28</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/>图像分类</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/201608_xception/ class=prev rel=prev title="Xception, Deep Learning with Depthwise Separable Convolutions"><i class="fas fa-angle-left fa-fw"></i>Xception, Deep Learning with Depthwise Separable Convolutions</a>
<a href=/201704_mobilenet-v1/ class=next rel=next title="MobileNets, Efficient Convolutional Neural Networks for MobileVision Applications">MobileNets, Efficient Convolutional Neural Networks for MobileVision Applications<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2022</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/about/ target=_blank rel="noopener noreferrer">Yangliuly1</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class=footer-line></div><div class=footer-line></div></div><script>"serviceWorker"in navigator&&(navigator.serviceWorker.register("/sw.min.js",{scope:"/"}).then(function(){}),navigator.serviceWorker.ready.then(function(){}))</script></footer></div><div id=fixed-buttons><a href=#back-to-top id=back-to-top-button class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><div class=assets><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/tablesort/tablesort.min.js></script><script type=text/javascript src=/lib/topbar/topbar.min.js></script><script type=text/javascript src=/lib/pjax/pjax.min.js></script><script type=text/javascript src=/js/theme.min.js defer></script></div><div class=pjax-assets><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:10},comment:{},data:{"desktop-header-typeit":"日落跌进迢迢星野,人间忽晚,山河已秋!","mobile-header-typeit":"日落跌进迢迢星野,人间忽晚,山河已秋!"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},table:{sort:!0},typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"desktop-header-typeit":["desktop-header-typeit"],"mobile-header-typeit":["mobile-header-typeit"]},duration:-1,speed:100}}</script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/typeit/typeit.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js defer></script><script type=text/javascript src=/lib/katex/auto-render.min.js defer></script><script type=text/javascript src=/lib/katex/copy-tex.min.js defer></script><script type=text/javascript src=/lib/katex/mhchem.min.js defer></script><script type=text/javascript src=/js/katex.min.js defer></script><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/copy-tex.min.css><noscript><link rel=stylesheet href=/lib/katex/copy-tex.min.css></noscript></div></body></html>