<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title class=pjax-title>Xception, Deep Learning with Depthwise Separable Convolutions - Yang</title><meta name=Description content><meta property="og:title" content="Xception, Deep Learning with Depthwise Separable Convolutions"><meta property="og:description" content="摘要：基于Inception v3是假设出发，即解耦通道相关性和空间相关性，进行简化，推导出深度可分离卷积，构建Inception v4网络。"><meta property="og:type" content="article"><meta property="og:url" content="https://Yangliuly1.github.io/201608_xception/"><meta property="og:image" content="https://Yangliuly1.github.io/images/avatar.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-04-28T21:57:27+08:00"><meta property="article:modified_time" content="2022-04-28T21:57:27+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://Yangliuly1.github.io/images/avatar.png"><meta name=twitter:title content="Xception, Deep Learning with Depthwise Separable Convolutions"><meta name=twitter:description content="摘要：基于Inception v3是假设出发，即解耦通道相关性和空间相关性，进行简化，推导出深度可分离卷积，构建Inception v4网络。"><meta name=application-name content="Yang"><meta name=apple-mobile-web-app-title content="Yang"><meta name=theme-color content="#f8f8f8"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://Yangliuly1.github.io/201608_xception/><link rel=prev href=https://Yangliuly1.github.io/201602_inception-v4/><link rel=next href=https://Yangliuly1.github.io/201608_densnet/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/fontawesome-free/all.min.css><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/animate/animate.min.css><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Xception, Deep Learning with Depthwise Separable Convolutions","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/Yangliuly1.github.io\/201608_xception\/"},"genre":"posts","keywords":"图像分类","wordcount":229,"url":"https:\/\/Yangliuly1.github.io\/201608_xception\/","datePublished":"2022-04-28T21:57:27+08:00","dateModified":"2022-04-28T21:57:27+08:00","publisher":{"@type":"Organization","name":"Yangliuly1"},"author":{"@type":"Person","name":"Yangliuly1"},"description":""}</script></head><body header-desktop=fixed header-mobile=auto><script type=text/javascript>function setTheme(e){document.body.setAttribute("theme",e),document.documentElement.style.setProperty("color-scheme",e==="light"?"light":"dark")}function saveTheme(e){window.localStorage&&localStorage.setItem("theme",e)}function getMeta(e){const t=document.getElementsByTagName("meta");for(let n=0;n<t.length;n++)if(t[n].getAttribute("name")===e)return t[n];return""}if(window.localStorage&&localStorage.getItem("theme")){let e=localStorage.getItem("theme");e==="light"||e==="dark"||e==="black"?setTheme(e):setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")}else"auto"==="light"||"auto"==="dark"||"auto"==="black"?(setTheme("auto"),saveTheme("auto")):(saveTheme("auto"),setTheme(window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light"));let metaColors={light:"#f8f8f8",dark:"#252627",black:"#000000"};getMeta("theme-color").content=metaColors[document.body.getAttribute("theme")]</script><div id=back-to-top></div><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=Yang><span class=header-title-pre><i class='far fa-edit fa-fw'></i></span><span id=desktop-header-typeit class=typeit></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/about/>关于 </a><a class=menu-item href=https://github.com/Yangliuly1 title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i> </a><span class="menu-item delimiter"></span><a href=# onclick=return!1 class="menu-item theme-select" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
<select class=color-theme-select id=theme-select-desktop title="Switch Theme"><option value=light>Light</option><option value=dark>Dark</option><option value=black>Black</option><option value=auto>Auto</option></select></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=Yang><span class=header-title-pre><i class='far fa-edit fa-fw'></i></span><span id=mobile-header-typeit class=typeit></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><a class=menu-item href=/posts/ title>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/about/ title>关于</a><a class=menu-item href=https://github.com/Yangliuly1 title=GitHub rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i></a><a href=# onclick=return!1 class="menu-item theme-select" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
<select class=color-theme-select id=theme-select-mobile title="Switch Theme"><option value=light>Light</option><option value=dark>Dark</option><option value=black>Black</option><option value=auto>Auto</option></select></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class="toc-content always-active" id=toc-content-auto><nav id=TableOfContents><ul><li><a href=#文献信息>文献信息</a></li><li><a href=#个人理解>个人理解</a></li><li><a href=#背景知识>背景知识</a></li><li><a href=#原理方法>原理方法</a><ul><li><a href=#1简化inception>1、简化Inception</a></li><li><a href=#2xception>2、Xception</a></li><li><a href=#3xception-网络结构>3、Xception 网络结构</a></li></ul></li><li><a href=#训练测试>训练测试</a></li><li><a href=#代码>代码</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></div><script>document.getElementsByTagName("main")[0].setAttribute("pageStyle","normal")</script><script>document.getElementsByTagName("main")[0].setAttribute("autoTOC","true")</script><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Xception, Deep Learning with Depthwise Separable Convolutions</h1><div class=post-meta><div class=post-meta-line><span class=post-author><i class="author fas fa-user-circle fa-fw"></i><a href=/about/ title=Author rel=author class=author>Yangliuly1</a>
</span>&nbsp;<span class=post-category>included in </span>&nbsp;<span class=post-category>category <a href=/categories/%E4%B8%93%E4%B8%9A%E8%AE%BA%E6%96%87/><i class="far fa-folder fa-fw"></i>专业论文</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2022-04-28>2022-04-28</time>&nbsp;<i class="far fa-edit fa-fw"></i>&nbsp;<time datetime=2022-04-28>2022-04-28</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;229 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;2 minutes&nbsp;</div></div><div class="details toc" id=toc-static kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#文献信息>文献信息</a></li><li><a href=#个人理解>个人理解</a></li><li><a href=#背景知识>背景知识</a></li><li><a href=#原理方法>原理方法</a><ul><li><a href=#1简化inception>1、简化Inception</a></li><li><a href=#2xception>2、Xception</a></li><li><a href=#3xception-网络结构>3、Xception 网络结构</a></li></ul></li><li><a href=#训练测试>训练测试</a></li><li><a href=#代码>代码</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></div><div class=content id=content><p>摘要：基于Inception v3是假设出发，即解耦通道相关性和空间相关性，进行简化，推导出深度可分离卷积，构建Inception v4网络。</p><h2 id=文献信息 class=headerLink><a href=#%e6%96%87%e7%8c%ae%e4%bf%a1%e6%81%af class=header-mark></a>文献信息</h2><table><thead><tr><th>信息</th><th>内容</th></tr></thead><tbody><tr><td>日期</td><td>2016.08</td></tr><tr><td>作者</td><td>François Chollet</td></tr><tr><td>机构</td><td>Google, Inc</td></tr><tr><td>来源</td><td>arXiv</td></tr><tr><td>链接</td><td><a href=https://arxiv.org/abs/1610.02357 target=_blank rel="noopener noreffer">Xception: Deep Learning with Depthwise Separable Convolutions</a></td></tr><tr><td>代码</td><td><a href rel>Code</a></td></tr></tbody></table><h2 id=个人理解 class=headerLink><a href=#%e4%b8%aa%e4%ba%ba%e7%90%86%e8%a7%a3 class=header-mark></a>个人理解</h2><blockquote><p><strong style=color:red>问题:</strong> 文章为了解决通道之间的相关性与空间相关性问题；</p><p><strong style=color:red>方法:</strong> 文章提出了深度可分离卷积替代Inception结构；</p><p><strong style=color:red>结论:</strong> ImageNet数据集上略优于Inception V3；</p><p><strong style=color:red>理解:</strong> 深度可分离卷积，Pointwith和Depthwise的先后关系，Xception是先用1x1卷积分组，然后每组进行3x3卷积但是大多实现还是3x3分组卷积+1x1点卷积，而第二点不同是点卷积输出是线性激活，没有使用激活函数，而是把激活函数调整到卷积前。</p><p><strong style=color:red>优化：</strong>常规卷积和深度可分离卷积之间存在discrete spectrum，其参数是用于执行空间卷积的独立通道空间段的数量。初始模块是这一范围的重点。作者在经验评估中表明，与常规的Inception模块相比，Inception模块的极端情况（深度可分离卷积）可能具有优势。但是，没有理由相信深度可分离卷积是最佳的。可能是discrete spectrum上的中间点位于常规的Inception模块与深度可分离的卷积之间，具有其他优势。这个问题留待将来调查。</p></blockquote><hr><h2 id=背景知识 class=headerLink><a href=#%e8%83%8c%e6%99%af%e7%9f%a5%e8%af%86 class=header-mark></a>背景知识</h2><p>深度可分离卷积（Depthwise Separable Convolution）率先是由 Laurent Sifre在其博士论文《Rigid-Motion Scattering For Image Classification》中提出。经典的MobileNet系列算法便是采用深度可分离卷积作为其核心结构。</p><h2 id=原理方法 class=headerLink><a href=#%e5%8e%9f%e7%90%86%e6%96%b9%e6%b3%95 class=header-mark></a>原理方法</h2><p>Xception取义自Extreme Inception，即Xception是一种极端的Inception。</p><h3 id=1简化inception class=headerLink><a href=#1%e7%ae%80%e5%8c%96inception class=header-mark></a>1、简化Inception</h3><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com//images/20220706213846.png width=35%>
<img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com//images/20220706213846.png width=35%></div><p>Inception的核心思想是将通道分成若干个不同感受野大小的通道，除了能获得不同的感受野，Inception还能大幅的降低参数数量。</p><p>以简化版本为例：对于一个输入的特征图，首先通过三组1x1卷积得到三组特征图，它和先使用一组1x1卷积得到特征图，再将这组特征图分成三组是完全等价的。假设1x1卷积核的个数都是k2， 3x3的卷积核的个数都是k2，输入特征图的通道数为m，那么这个简单版本的参数个数为：</p><p>$$
m \times k_1 \times 1 \times 1 + 3 \times 3 \times 3 \times \frac{k_1}{3} \times \frac{k_2}{3} = m \times k_1 + 3 \times k_1 \times k_2
$$</p><p>对比相同通道数，但是没有分组的普通卷积，普通卷积的参数数量为：
$$
m \times k_1 \times 1 \times 1 + 3 \times 3 \times k_1 \times k_2
$$</p><p>Inception与普通卷积的参数数量约为Inception的三倍。</p><h3 id=2xception class=headerLink><a href=#2xception class=header-mark></a>2、Xception</h3><p>Inception是将3x3卷积分成3组，考虑一种极端的情况，将Inception的1x1得到的k1个通道的特征图完全分开，也就是使用k1个不同的卷积分别在每个通道上进行卷积，它的参数数量是：</p><p>$$
m \times k_1 + k_1 \times 3 \times 3
$$
更多时候作者希望两组卷积的输出特征图相同，这里我们将Inception的1x1卷积的通道数设为k2，即参数数量为</p><p>$$
m \times k_2 + k_2 \times 3 \times 3
$$
它的参数数量是普通卷积的$\frac{1}{k1}$，作者把这种形式的Inception叫做Extreme Inception，使用1x1卷积来映射跨通道相关性，然后分别映射每个输出通道的空间相关性：</p><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com//images/20220706213847.png width=75%></div><h3 id=3xception-网络结构 class=headerLink><a href=#3xception-%e7%bd%91%e7%bb%9c%e7%bb%93%e6%9e%84 class=header-mark></a>3、Xception 网络结构</h3><p>在搭建GoogLeNet网络时，作者一般采用堆叠Inception的形式，同理在搭建由Extreme Inception构成的网络的时候也是采用堆叠的方式，论文中将这种形式的网络结构叫做Xception。</p><p>深度可分离卷积等价于Xception，但存在两点不同：</p><ol><li><p>区别之一就是先计算Pointwise卷积和先计算Depthwise的卷积的区别。</p></li><li><p>在MobileNet v2中，指出bottleneck的最后一层1x1卷积核为线性激活时能够更有助于减少信息损耗，这也就是Xception和深度可分离卷积（准确说是MobileNet v2）的第二个不同点。</p></li></ol><div align=center><img src=https://cloud-resources-data.oss-cn-chengdu.aliyuncs.com//images/20220706213847.png width=75%></div><h2 id=训练测试 class=headerLink><a href=#%e8%ae%ad%e7%bb%83%e6%b5%8b%e8%af%95 class=header-mark></a>训练测试</h2><p>由于它们在规模上的相似性，我们选择将Xception与Inception V3架构进行比较：Xception和Inception V3具有几乎相同数量的参数，因此任何性能差距都不能归因于网络参数量的差异。我们对两个图像分类任务进行了比较：一个是ImageNet数据集上著名的1000类单标签分类任务，另一个是大规模JFT数据集上17000类多标签分类任务。</p><p><strong>JFT数据集</strong></p><p>JFT是用于大型图像分类数据集的内部Google数据集，其中包括超过3.5亿张高分辨率图像，这些图像带有来自17,000个类别的标签的注释。 为了评估在JFT上训练的模型的性能，我们使用了辅助数据集FastEval14k。
FastEval14k是14,000张图像的数据集，具有来自6,000个类别的密集注释（平均每张图像36.5个标签）。在此数据集上，我们使用mAP对前100个预测（MAP @100）进行评估，并对每个类别对MAP@100的贡献进行加权，并给出一个分数，以估算该类别在社交媒体图像中的普遍程度（因此很重要）。此评估程序旨在从社交媒体上捕获频繁出现的标签上的效果，这对于Google的生产模型至关重要。</p><p><strong>优化器配置</strong></p><p>ImageNet：Optimizer=SGD，Momentum=0.9，Initial learning rate=0.045，Learning rate decay=decay of rate 0.94 every 2 epochs
JFT：Optimizer=RMSprop，Momentum=0.9，Initial learning rate=0.001，Learning rate decay=decay of rate 0.9 every 3,000,000 samples</p><p><strong>正则化配置</strong></p><p>Weight decay：Inception v3为0.00004，Xception为0.00001
Dropout：ImageNet为0.5，JFT无，因为数据太多，不太可能过拟合
Auxiliary loss tower：没有使用</p><p><strong>训练配置</strong></p><p>所有网络均使用TensorFlow框架实施，并分别在60个NVIDIA K80 GPU上进行了培训。 对于ImageNet实验，我们使用具有同步梯度下降的数据并行性来获得最佳的分类性能，而对于JFT，我们使用异步梯度下降来加快训练速度。 ImageNet实验每个大约花费3天，而JFT实验每个大约花费一个月。 JFT模型没有经过完全收敛的训练，而每个实验将花费三个月以上的时间。</p><p><strong>与Inception V3相比</strong></p><ol><li><p>在分类性能上，Xception在ImageNet领先较小，但在JFT上领先很多。</p></li><li><p>在参数量和速度，Xception参数量少于Inception，但速度更快。</p></li><li><p>作者还比较了residual connections，有了性能更强；还有点卷积之后要不要激活函数，没有非线性层效果最好。</p></li></ol><h2 id=代码 class=headerLink><a href=#%e4%bb%a3%e7%a0%81 class=header-mark></a>代码</h2><p>注意：实验发现，深度可分离卷积中的卷积层之间不加非线性激活函数的效果相较于加入非线性激活函数来说会更好一些，而是先激活，再深度可分离卷积，再加上归一化操作，最后跳跃链接相加。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1>#深度可分离卷积</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>SeparableConv2d</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>in_channels</span><span class=p>,</span><span class=n>out_channels</span><span class=p>,</span><span class=n>kernel_size</span><span class=p>,</span><span class=n>stride</span><span class=p>,</span><span class=n>padding</span><span class=p>,</span><span class=n>dilation</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>bias</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>SeparableConv2d</span><span class=p>,</span><span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1># 逐通道卷积：groups=in_channels=out_channels</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span><span class=n>in_channels</span><span class=p>,</span><span class=n>kernel_size</span><span class=p>,</span><span class=n>stride</span><span class=p>,</span><span class=n>padding</span><span class=p>,</span><span class=n>dilation</span><span class=p>,</span><span class=n>groups</span><span class=o>=</span><span class=n>in_channels</span><span class=p>,</span><span class=n>bias</span><span class=o>=</span><span class=n>bias</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 逐点卷积：普通1x1卷积</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>pointwise</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span><span class=n>out_channels</span><span class=p>,</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>padding</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span><span class=n>dilation</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>groups</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span><span class=n>bias</span><span class=o>=</span><span class=n>bias</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span><span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pointwise</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=参考文献 class=headerLink><a href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae class=header-mark></a>参考文献</h2></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2022-04-28</span></div><div class=post-info-license></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw"></i>&nbsp;<a href=/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/>图像分类</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/201602_inception-v4/ class=prev rel=prev title="Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning"><i class="fas fa-angle-left fa-fw"></i>Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning</a>
<a href=/201608_densnet/ class=next rel=next title="Densely Connected Convolutional Networks">Densely Connected Convolutional Networks<i class="fas fa-angle-right fa-fw"></i></a></div></div><div id=comments></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2022</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/about/ target=_blank rel="noopener noreferrer">Yangliuly1</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class=footer-line></div><div class=footer-line></div></div><script>"serviceWorker"in navigator&&(navigator.serviceWorker.register("/sw.min.js",{scope:"/"}).then(function(){}),navigator.serviceWorker.ready.then(function(){}))</script></footer></div><div id=fixed-buttons><a href=#back-to-top id=back-to-top-button class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw"></i></a></div><div class=assets><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/tablesort/tablesort.min.js></script><script type=text/javascript src=/lib/topbar/topbar.min.js></script><script type=text/javascript src=/lib/pjax/pjax.min.js></script><script type=text/javascript src=/js/theme.min.js defer></script></div><div class=pjax-assets><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:10},comment:{},data:{"desktop-header-typeit":"日落跌进迢迢星野,人间忽晚,山河已秋!","mobile-header-typeit":"日落跌进迢迢星野,人间忽晚,山河已秋!"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},table:{sort:!0},typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"desktop-header-typeit":["desktop-header-typeit"],"mobile-header-typeit":["mobile-header-typeit"]},duration:-1,speed:100}}</script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/typeit/typeit.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js defer></script><script type=text/javascript src=/lib/katex/auto-render.min.js defer></script><script type=text/javascript src=/lib/katex/copy-tex.min.js defer></script><script type=text/javascript src=/lib/katex/mhchem.min.js defer></script><script type=text/javascript src=/js/katex.min.js defer></script><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=preload as=style onload='this.onload=null,this.rel="stylesheet"' href=/lib/katex/copy-tex.min.css><noscript><link rel=stylesheet href=/lib/katex/copy-tex.min.css></noscript></div></body></html>